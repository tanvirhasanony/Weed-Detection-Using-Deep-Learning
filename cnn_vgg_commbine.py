# -*- coding: utf-8 -*-
"""CNN_VGG_commbine.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Qd8OLQvVsl51sS--EvHptAhHe3wJWrhG
"""

import tensorflow

#get acess google drive data into google colab

from google.colab import drive
drive.mount('/content/drive')

from zipfile import ZipFile
file_name = "/content/drive/MyDrive/dataset1.zip"
with ZipFile(file_name,'r') as zip:
  zip.extractall()
  print('unzip successfully')

# Importing the Keras libraries and packages
from tensorflow.keras.models import Sequential
from tensorflow.keras import layers, Model
from tensorflow.keras.layers import  Dropout
from tensorflow.keras.applications.vgg16 import VGG16

from keras.preprocessing.image import ImageDataGenerator
# data augmentation
# our data set contains less number of data for this reason we use data augmentation
train_datagen = ImageDataGenerator(
        rotation_range=30,  # randomly rotate images 30 degrees
        zoom_range = 0.2, # Randomly zoom image 20%
        width_shift_range=0.1,  # randomly shift images horizontally 10%
        height_shift_range=0.1,  # randomly shift images vertically 10%
        rescale=1/255, #scaling between 0 to 1
        shear_range=0.2 ,# Randomly share image 20%
        horizontal_flip=True,  # randomly flip images
        fill_mode='nearest') 

test_datagen = ImageDataGenerator(rescale = 1./255)

training_set = train_datagen.flow_from_directory('/content/dataset1/train_set',
                                                 target_size = (224, 224),
                                                 batch_size = 2,
                                                 class_mode = 'binary')

test_set = test_datagen.flow_from_directory('/content/dataset1/test_set',
                                            target_size = (224, 224),
                                            batch_size = 1,
                                            class_mode = 'binary')

# re-size all the images to this
IMAGE_SIZE = [224, 224]

# add preprocessing layer to the front of VGG
vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)

vgg.summary()

# don't train existing weights
for layer in vgg.layers:
  layer.trainable = False

model1 = Sequential()
#add vgg-16
model1.add(vgg)
 
# adding Flattening layer
model1.add(layers.Flatten())
 
# adding fully connected layer
model1.add(layers.Dense(units=250, activation='relu'))

#reducing overfitting problem
model1.add(Dropout(0.5))
 
#adding output layer
model1.add(layers.Dense(units=1, activation='sigmoid'))

model1.summary()

# Compiling the CNN
# here we use adam optimizer 
#here we use binary_crossentropy because our dataset only have 2 types of data
model1.compile(optimizer ='adam',loss='binary_crossentropy',metrics=['accuracy'])

training_set.class_indices

# fit the model
r = model1.fit_generator(
  training_set,
  validation_data=test_set,
  epochs=50,
  steps_per_epoch=9739, # steps_per_epocs  * batch_size = traindata set
  validation_steps=4837 # validation_steps  * batch_size = testdata set
)

import matplotlib.pyplot as plt

# plot the loss
plt.plot(r.history['loss'], label='train loss')
plt.plot(r.history['val_loss'], label='val loss')
plt.legend()
plt.show()
#plt.savefig('LossVal_loss')

# plot the accuracy
plt.plot(r.history['accuracy'], label='train acc')
plt.plot(r.history['val_accuracy'], label='val acc')
plt.legend()
plt.show()
#plt.savefig('AccVal_acc')

model1.evaluate(test_set)

# save it as a h5 file
from tensorflow.keras.models import load_model
model1.save('/content/drive/MyDrive/1cnn_vgg16.h5')

from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image

model=load_model('/content/drive/MyDrive/1cnn_vgg16.h5')

sample = "/content/drive/MyDrive/weed1.jpg"

from keras.preprocessing import image
sample_image = image.load_img(sample,target_size=(224,224))

sample_image = image.img_to_array(sample_image)
sample_image.shape

import numpy as np
sample_image = np.expand_dims(sample_image,axis=0)
sample_image.shape

sample_image = sample_image/255

prediction = model.predict(sample_image)
print(prediction)
print(prediction[0][0])
print( np.argmax(prediction, axis=1))

if prediction[0][0] < 0.5:
    output = 'maiz'
else:
    output = 'weed'
print(output)